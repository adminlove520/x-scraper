# 🎯 X-Scraper 采集技巧指南

在使用 X-Scraper 进行大规模数据采集时，了解 Twitter/X.com 的限制和规则至关重要。

## 📋 目录

- [API 限制说明](#api-限制说明)
- [如何提高采集效率](#如何提高采集效率)
- [防封号建议](#防封号建议)
- [数据处理技巧](#数据处理技巧)

## ⚖️ API 限制与轮换说明

Twitter API v2 对 Bearer Token 有严格的速率限制。本项目内置了 **Token 自动轮换机制**：

- **配置方式**：在 `TWITTER_BEARER_TOKEN` 环境变量中使用逗号分隔多个 Token（如 `token1,token2`）。
- **轮换触发**：当某个 Token 遇到 429 (Rate Limit) 错误时，系统会自动切到下一个 Token。
- **休眠逻辑**：如果所有 Token 都报错，系统会休眠 15 分钟后再尝试。

**建议**：在 `app/engine.py` 中，我们为每次请求设置了 `asyncio.sleep(2)`，这在大规模轮询时有助于保持速率稳定。

## 📈 如何提高采集效率

1. **分布式订阅**：
   - 尽量将不同类型的账号分开订阅。
   - 使用 Webhook 处理公用账号，减小重复请求的压力。

2. **精简请求字段**：
   - 我们在 `XCrawler` 中仅请求了必要的推文文本和互动数据。如果不需要实体（Entities），可以进一步精简。

3. **利用 GitHub Actions**：
   - 对于不需要秒推的全局账号，使用 GitHub Actions 的 Cron 模式，避免常驻服务器资源消耗。

## 🛡️ 防封号建议

- **合理间隔**：不要尝试每秒钟抓取一次同一个用户。
- **混合模式**：如果你有多个 Bearer Token，可以在 `XCrawler` 中实现轮换（本项目暂未包含轮换逻辑，但结构上易于扩展）。
- **遵守 ToS**：只通过官方 API 访问公开数据。

## 📊 数据处理技巧

- **去重逻辑**：程序会在 `data/processed_ids.json` 中保存已处理的 ID。请务必备份此文件，防止系统重启后重新发送已推送过的推文。
- **JSON 解析**：如果您需要对采集的数据进行离线分析，可以使用 `data/batch_results.json` 中的结构。
